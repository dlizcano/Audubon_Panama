---
title: "BFI - Carbono, Parita Bay, Panama"
subtitle: "A model selection approach "
date: "`r Sys.Date()`"
author: 
  - name: Diego Lizcano
    orcid: https://orcid.org/0000-0002-9648-0576
  - name: Jorge Velásquez-Tibata
    orcid: https://orcid.org/0000-0002-7773-7348
license: CC BY-SA
toc: true
format: 
  html:
    theme: cosmo
    code-fold: true
    code-block-bg: "gray70"
citation: true
google-scholar: true
bibliography: C:/CodigoR/AudubonPanama/grateful-refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  dev.args = list(type = "cairo-png"),
  fig.width = 7,
  fig.height = 5,
  fig.align = "center",
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  cache=FALSE)
```

## Question

Is carbon, measured at AGBsubplot a good predictor of BFI?

## Set up analysis

Load libraries and set some options.

```{r set_up}
#| warning: false
#| message: false

library(readxl) # Read Excel Files # Read Excel Files
library(gt) # Easily Create Presentation-Ready Display Tables
library(lubridate) # Make Dealing with Dates a Little Easier
library(stringr) # Simple, Consistent Wrappers for Common String Operations
library(readxl) # Read Excel Files # Read Excel Files
library(sf) # Simple Features for R
library(MuMIn) # multimodel inference
library(metafor) # Meta-Analysis Package for R
eval(metafor:::.MuMIn) # helper functions we need so that MuMIn and metafor can interact 
library(visreg) # see trend

library(terra) # Spatial Data Analysis
library(sjPlot) # Data Visualization for Statistics in Social Science
# library(mapview)
library(corrplot) # Visualization of a Correlation Matrix
library(DT) # A Wrapper of the JavaScript Library 'DataTables'
library(grateful) # Facilitate Citation of R Packages
library(geodata) # worlclim data

library(see) # Model Visualisation Toolbox for 'easystats' and 'ggplot2'
library(performance) # Assessment of Regression Models Performance

library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(ggeffects) # Create Tidy Data Frames of Marginal Effects for 'ggplot' from


options(scipen=99999)
options(max.print=99999)
options(stringsAsFactors=F)
```

## Load Data

```{r}
#| warning: false
#| message: false


Subplots_coord <- read_excel("C:/CodigoR/AudubonPanama/data/2024 may 29 Velasquez Muestreo Acustico ParB jhs data.xlsx") |> mutate(site=Name) 

Subplots_coord2 <- read_excel("C:/CodigoR/AudubonPanama/data/2024 may 30 Hoyos ParB Subplots Acustinc monitoring.xlsx") |> mutate(site=plotId) 


covs_manyraster <- rast("C:/CodigoR/AudubonPanama/raster/covs_many_raster.tif")


# covs <- read_csv("C:/CodigoR/AudubonPanama/shp/sites_covs_parita_nona.csv") |> mutate(site=Name) 

BFI_site<- read.csv("C:/CodigoR/AudubonPanama/data/BFI_site.csv", header = TRUE) |> left_join(Subplots_coord)
# convierte covs a puntos terra
# puntos <- vect(BFI_site, geom=c("Longitude", "Latitude"), crs="EPSG:4326")
# convierte a sf
covs_all<- sf::st_as_sf(BFI_site, coords = c("Long", "Lat"),
           crs = "EPSG:4326")

Carbono <- sf::st_as_sf(Subplots_coord2, coords = c("Long", "Lat"),
           crs = "EPSG:4326")

# see which is closer
# mapview(Audiomoths, alpha = 0) + mapview(Carbono)

# get extra Bio vars 9 and 17 requested by Jorge
bios <- worldclim_tile(var = "bio", res = 0.5,
  lat=8.000535, lon=-80.39227, path = "C:/CodigoR/AudubonPanama/raster/")

bio_covs <- terra::extract(bios, covs_all)
otherrast_covs <- terra::extract(covs_manyraster, covs_all)


covs_all$bio9 <- bio_covs$tile_28_wc2.1_30s_bio_9
covs_all$bio17 <- bio_covs$tile_28_wc2.1_30s_bio_17
covs_all$forest_integrity<- otherrast_covs$forest_integrity
covs_all$NDVI<- otherrast_covs$NDVI

# remove tology
covs_all <- as.data.frame(covs_all)[,-33]
# LUC_Impact
```

## Correlation in sites (points) where the Audiomoth was installed

```{r}
# extract values from raster 
# covs_all1 <- terra::extract(covs_many_raster, puntos) 

# saved to avoid conflict between terra::extract and dplyr
# saveRDS(covs_all1, "C:/CodigoR/AudubonPanama/data/BFI/covs_all.RDS")
# save(covs_all, file = "C:/CodigoR/AudubonPanama/data/BFI/covs_all.Rda")
# covs_all <- readRDS("C:/CodigoR/AudubonPanama/data/BFI/covs_all.RDS")
#load the rda file
# covs_all <- load(file = "C:/CodigoR/AudubonPanama/data/BFI/covs_all.Rda")
# write.csv(covs_all)

# covs_all$site <- puntos$site # ad site name

# change NA to 0 
# covs_all <- substr(covs_all, NA, 0) #replace in terra
# covs_all <- BFI_site
covs_all[is.na(covs_all)] <- 0
M = cor(covs_all[,c(18:27, 30:32)]) # removes ID and site an many others 
corrplot(M)

```

> covariate removed: \[25\] "Average TC top 50 cm";  \[26\] "Average TN top 50 cm"; \[22\] "BGC"

```{r}
#| warning: false
#| message: false
#| eval: false
#| echo: false


# many_rasters <- list(AGB_Spawn, human_foot, NDVI, river, canopy, roads, forest_integrity, coast)
# terra stack
# # covs_many_raster <- terra::rast(many_rasters)
# names(covs_many_raster) <- c("BGB_Spawn", "AGB_Spawn",
#                         "human_foot", "NDVI", "river",  
#                         "canopy", "roads", "forest_integrity",
#                         "coast")
# 
# writeRaster(covs_many_raster, "C:/CodigoR/AudubonPanama/raster/covs_many_raster.tif", overwrite=TRUE)

# covs_many_raster <- rast("C:/CodigoR/AudubonPanama/raster/covs_many_raster.tif")

# extract values from raster 
# covs_all <- terra::extract(covs_many_raster, puntos) 
# covs_all$site <- puntos$site # ad site name

# change NA to 0 
# covs_all <- substr(covs_all, NA, 0) #replace in terra
# covs_all[is.na(covs_all)] <- 0


```

## Which model predicts BFI the best?

Information-theoretic approaches provide methods for model selection and (multi)model inference that differ quite a bit from more traditional methods based on null hypothesis testing (e.g., Anderson, 2008; Burnham & Anderson, 2002). These methods can also be used in the meta-analytic context when model fitting is based on likelihood methods.

We will now examine the fit and plausibility of various models, focusing on models that contain none, one, and up to seven of these possible predictors covariates of BFI.

With level = 1, we stick to models with main effects only. This implies that there are $2^7$ = 128 possible models in the candidate set to consider. Since we want to keep the results for all these models (the default is to only keep up to 100 model fits), We set confsetsize=128. With crit="AIC", we select the Akaike Information Criterion, in this case: the AIC that we would like to compute for each model and that should be used for model selection and multimodel inference.

### lets put all data BFI and all covariates in the same table

```{r}

# put in a table
dat1 <- covs_all# BFI_site # |> left_join(covs_all)
# dat <- dat1 |> dplyr::select("bfi_unscaled",  
#                              "DBH_cm", 
#                              "H_m", 
#                              "AGBplot", 
#                              "AGBsubplot", 
#                              "BGC", 
#                              "Phosphorus", "pHw", "Conductivity", "LUC_Impact", "Mangrove_typology") #bfi_scaled_scale
dat <- dat1[,c(5,19,20,21,26,28,30,31,32)]

```

### Next, we fit all the posible models with function dredge

Now we can fit all 128 models and examine those models whose AICc value is no more than 2 units away from that of the best model.

```{r}

library(MASS) # stepAIC

full <- lm(bfi_unscaled~., data=dat)


# Now we can fit all 128 models and examine those models whose AICc value is no more than 2 units away from that of the best model with:
options(na.action = "na.fail")
res <- dredge(full, 
              rank = "AIC", # can be AICc as well
              beta="sd", 
              # extra = c("R^2"),
              m.lim = c(1, 2))
# subset(res, delta <= 2, recalc.weights=FALSE)
res # summary(model.avg(res))
plot(res)





```

The graph shows the number of times the variable was selected in each model

### Now we refit best linear model

```{r}

# 8. Refit best linear model
bestmodel <- get.models(res, 1)[[1]]
z <- lm(bestmodel, data = dat)
tab_model(summary(z), bootstrap=TRUE)



```

According to lowest AIC of 128 models, the Best model is:

$$
BFIunscaled \sim H_m + LUC impact + intercept 
$$

### Checking assumptions

```{r}


# result2 <- check_normality(z)
# plot(result2, type = "density")
# plot(result2, type = "qq")
# plot(result2, type = "pp")
# 
# result3 <- check_heteroscedasticity(z)
# plot(result3)
# check_predictions(z, check_range = TRUE)


out <- check_model(z)
plot(out, type = "discrete_both")
```

In seems our "best" model, according to the AIC is z = $$BFIunscaled \sim H_m + LUC impact + intercept$$

Do not meet normality fully, and the posterior predictive check is not that good. But normality is that important?. Lets relax that assumption...

```{r}
#| warning: false
#| message: false
#| eval: false
#| echo: false

### And finally see the trends

# visreg(z, xvar = c("BGC"))
# visreg(z, xvar = c("LUC_Impact"))

```

#### is there any interaction?

Lets Include all possible two-way interactions between: H_m, pHw, AGBsubplot and forest_integrity to finally select the model with lowest AIC.

```{r}

# put in a table
# dat2 <- dat1 |>  dplyr::select("bfi_unscaled", 
#                               "H_m" ,
#                               `BGC`,
#                                 "pHw")

dat2 <- dat1[,c(5,19,21,26,32)]
# 12. Include all two-way interactions
z2full <- lm(bfi_unscaled ~ (.)^2, data = dat2)
z2 <- stepAIC(z2full, upper = ~., lower = ~1, direction = "both")
tab_model(summary(z2))

```

The answer is: it seems to be an interaction between H_m, BGC and AGBsubplot So another plausible model is z2 =  $$BFI unscaled \sim H_m + AGBsubplot + Forest Integrity + H_m:Forest Integrity$$


## Which model can be the best?

### Lets compare the fix effect model performance of z1 and z2 and several aditional models including LUC_Impact

We use the models:  

z1 <- lm(bfi_unscaled ~  H_m + LUC impact + intercept, dat).  
z2 <- lm(bfi_unscaled ~ H_m + AGBsubplot + forest_integrity + H_m:forest_integrity), dat).  
z3 <- lm(bfi_unscaled ~ H_m + AGBsubplot + forest_integrity + H_m:forest_integrity + *LUC_Impact*), dat).  
z4 <- lm(bfi_unscaled ~ AGBsubplot + H_m * *LUC_Impact*, dat).  
z5 <- lm(bfi_unscaled ~ AGBsubplot + H_m + forest_integrity + *LUC_Impact*, dat).  
z6 <- lm(bfi_unscaled ~ (H_m)^2 * AGBsubplot + *LUC_Impact*, dat).  

```{r}

z3 <- lm(bfi_unscaled ~ H_m + AGBsubplot + forest_integrity + H_m:forest_integrity + LUC_Impact, dat)
z4 <- lm(bfi_unscaled ~ AGBsubplot + H_m * LUC_Impact, dat)
z5 <- lm(bfi_unscaled ~ AGBsubplot + H_m + forest_integrity + LUC_Impact, dat)
z6 <- lm(bfi_unscaled ~ (H_m)^2 * AGBsubplot + LUC_Impact, dat)

result1 <- compare_performance(z,z2,z3,z4,z5,z6,  rank=TRUE)

DT::datatable(result1)
plot(result1)

# test_performance(z, z2, z3)
# test_bf(z, z2, z3)
# lmtest::lrtest(z, z2, z3)

```

Larger values indicate better model performance. Hence, points closer to the center indicate worse fit indices.

> best model is again z2

$$
BFIunscaled \sim H_m + AGBsubplot + ForestIntegrity + H_m:ForestIntegrity
$$

```{r}
sjPlot::tab_model(z2)
```

#### Lets see how well z2 meet normality asumptions


```{r}

result4 <- check_normality(z2)
plot(result4, type = "density")
plot(result4, type = "qq")
plot(result4, type = "pp")

out3 <- check_model(z2, panel=TRUE)
plot(out3, type = "discrete_both")



```
#### Lets see the model coeficients and predictions for z2

```{r}

# visreg(z2, xvar = c("DBH_cm", "H_m", "pHw"))
dat4 <- predict_response(z2, terms = c("AGBsubplot", "H_m", "forest_integrity"))
plot(dat4, facets = TRUE)



plot_model(z2, type = "est")
# plot_model(lm2, type = "re") # in case random effect
plot_model(z2, type = "pred")
```

### Lets try some mix models with random effects in LUC_Impact
We used the models:  


lm4 <- glmer(bfi_unscaled ~ AGBsubplot + (1|LUC_Impact), data = dat).  
lm5 <- glmer(bfi_unscaled ~ AGBsubplot + forest_integrity + (1|LUC_Impact), data =dat).  
lm6 <- glmer(bfi_unscaled ~ AGBsubplot + H_m + (1|LUC_Impact), data = dat).  
lm7 <- glmer(bfi_unscaled ~ AGBsubplot + H_m + LUC_Impact + (1|LUC_Impact), data = dat).  
lm8 <- glmer(bfi_unscaled ~ AGBsubplot * LUC_Impact + H_m + (1|LUC_Impact), data = dat).  
lm9 <- glmer(bfi_unscaled ~ AGBsubplot + H_m + LUC_Impact + (1|LUC_Impact), data = dat).  


```{r}

library(lme4)

lm4 <- glmer(bfi_unscaled ~ AGBsubplot + (1|LUC_Impact), data =  dat)
lm5 <- glmer(bfi_unscaled ~ AGBsubplot + forest_integrity + (1|LUC_Impact), data =  dat)
lm6 <- glmer(bfi_unscaled ~ AGBsubplot + H_m + (1|LUC_Impact), data =  dat)
lm7 <- glmer(bfi_unscaled ~ AGBsubplot + H_m + LUC_Impact + (1|LUC_Impact), data =  dat)
lm8 <- glmer(bfi_unscaled ~ AGBsubplot * LUC_Impact + H_m + (1|LUC_Impact), data =  dat)
lm9 <- glmer(bfi_unscaled ~ AGBsubplot + H_m + LUC_Impact + (1|LUC_Impact), data =  dat)


```

### Lets compare the mix models with random effects on LUC_Impact

```{r}



result2 <- compare_performance(lm4,lm5,lm6,lm7,lm8,lm9,  rank=TRUE)

DT::datatable(result2)
plot(result2)

# test_performance(z, z2, z3)
# test_bf(z, z2, z3)
# lmtest::lrtest(z, z2, z3)

```

> best model is lm6

$$
BFIunscaled \sim AGBsubplot + H_m + (1|LUC impact)
$$

```{r}
sjPlot::tab_model(lm6)
```


#### Lets see wow well lm6 meet model assumptions 


```{r}

result2 <- check_normality(lm6)
plot(result2, type = "density")
plot(result2, type = "qq")
plot(result2, type = "pp")

out4 <- check_model(lm6, panel=TRUE)
plot(out4, type = "discrete_both")


```

#### Lets see the model coeficients and predictions for lm6 

```{r}

# visreg(z3, xvar = c("DBH_cm", "H_m", "pHw"))
dat2 <- predict_response(lm6, terms = c("AGBsubplot",  "H_m", "LUC_Impact"))
plot(dat2, facets = TRUE)

plot_model(lm6, type = "est")
# plot_model(lm2, type = "re") # in case random effect
plot_model(lm6, type = "pred")

```



## Result of model selection

```{r}
library(report)
report::report(z2)
report::report(lm6)
```

### fix effect model 

We fitted a linear model (estimated using OLS) to predict bfi_unscaled with H_m,
AGBsubplot and forest_integrity (formula: bfi_unscaled ~ H_m + AGBsubplot +
forest_integrity + H_m:forest_integrity). The model explains a statistically significant
and substantial proportion of variance (R2 = 0.62, F(4, 11) = 4.47, p = 0.022, adj. R2 =
0.48). The model's intercept, corresponding to H_m = 0, AGBsubplot = 0 and
forest_integrity = 0, is at 2374.34 (95% CI [1850.24, 2898.43], t(11) = 9.97, p < .001).
Within this model:

  - The effect of H m is statistically significant and negative (beta = -74.95, 95% CI
[-120.89, -29.01], t(11) = -3.59, p = 0.004; Std. beta = -0.93, 95% CI [-1.49, -0.37])
  - The effect of AGBsubplot is statistically non-significant and positive (beta = 1.01,
95% CI [-0.23, 2.25], t(11) = 1.79, p = 0.101; Std. beta = 0.51, 95% CI [-0.12, 1.15])
  - The effect of forest integrity is statistically non-significant and negative (beta =
-105.07, 95% CI [-215.97, 5.82], t(11) = -2.09, p = 0.061; Std. beta = 0.25, 95% CI
[-0.25, 0.76])
  - The effect of H m × forest integrity is statistically significant and positive (beta =
9.40, 95% CI [2.10, 16.69], t(11) = 2.83, p = 0.016; Std. beta = 0.74, 95% CI [0.17,
1.31])

Standardized parameters were obtained by fitting the model on a standardized version of
the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald
t-distribution approximation.


### mixed effect model

We fitted a linear mixed model (estimated using REML and nloptwrap optimizer) to predict
bfi_unscaled with AGBsubplot and H_m (formula: bfi_unscaled ~ AGBsubplot + H_m). The
model included LUC_Impact as random effect (formula: ~1 | LUC_Impact). The model's total
explanatory power is substantial (conditional R2 = 0.33) and the part related to the
fixed effects alone (marginal R2) is of 0.20. The model's intercept, corresponding to
AGBsubplot = 0 and H_m = 0, is at 1861.87 (95% CI [1586.25, 2137.49], t(11) = 14.87, p <
.001). Within this model:

  - The effect of AGBsubplot is statistically non-significant and positive (beta = 0.45,
95% CI [-0.96, 1.86], t(11) = 0.70, p = 0.497; Std. beta = 0.23, 95% CI [-0.49, 0.95])
  - The effect of H m is statistically non-significant and negative (beta = -19.39, 95% CI
[-40.41, 1.63], t(11) = -2.03, p = 0.067; Std. beta = -0.57, 95% CI [-1.19, 0.05])

Standardized parameters were obtained by fitting the model on a standardized version of
the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald
t-distribution approximation.


## Conclusion

> The answer to the initial question: Is carbon, measured at AGBsubplot a good predictor of BFI? is YES!

In both models (fix effects model with interaction and mixed effect) carbon at AGBsubplot shows a positive relationship with BFI. However the AGBsubplot in both "best" models is not significant. 


## Package Citation

```{r }
pkgs <- cite_packages(output = "paragraph", out.dir = ".")
knitr::kable(pkgs)
# pkgs
```

## Sesion info

```{r}
print(sessionInfo(), locale = FALSE)
```
